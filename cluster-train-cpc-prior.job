#!/bin/bash

# Train CNN prior over VQ-VAE embeddings
#
# USAGE:
# sbatch cluster-train-vqvae.job
#
#SBATCH --job-name=cpc-prior
#SBATCH --mail-user=echandler@uchicago.edu
#SBATCH --mail-type=ALL
#
#SBATCH --output=/home/echandler/DeepL/final-project/mi-vqvae/output/%j.%N.stdout
#SBATCH --error=/home/echandler/DeepL/final-project/mi-vqvae/output/%j.%N.stderr
#
#OPTIONS FOR JOB SIZE:
#SBATCH --partition=general
#SBATCH --nodes=1
# NOTE: always set ntasks==gpus or else it doesnt allocate right?
#SBATCH --ntasks=1
#SBATCH --gpus=1
#SBATCH --gpus-per-task=1
#SBATCH --mem-per-cpu=32G
#SBATCH --time=03:59:00
#

PROJECT_ROOT="/home/echandler/DeepL/final-project"
VQVAE_DIR="$PROJECT_ROOT/mi-vqvae"
VQVAE_REPO="$VQVAE_DIR/pytorch-vqvae"
CELEBA_DIR="/net/scratch/echandler/datasets/img_align_celeba"
MNIST_DIR="$PROJECT_ROOT/data/mnist"

# Best encoder
MODEL_FILE="$VQVAE_REPO/models/celeba-b256-f32-opt-sched-encoder/best.pt"

echo "Env sanity check: python exe: `which python`"
echo "Env sanity check: hostname: `hostname`"
echo "Env sanity check: cuda devices: $CUDA_VISIBLE_DEVICES"

cd "$VQVAE_REPO"
python train_prior.py \
    --data-folder "$CELEBA_DIR" \
    --dataset celeba \
    --model-file "$MODEL_FILE" \
    --model cpc \
    --run-name sampler-cpc-m1 \
    --batch-size 64 \
    --num-epochs 50 \
    --num-workers 2 \
    --num-future 32 \
    --device cuda \
    --logger-lvl INFO
